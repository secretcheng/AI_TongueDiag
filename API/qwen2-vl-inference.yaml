model_name_or_path: xxx
template: qwen2_vl
infer_backend: huggingface  # choices: [huggingface, vllm]
# trust_remote_code: true

temperature: 0.01
top_p: 0.1
top_k: 20
max_new_tokens: 8192
cutoff_len: 12800

# vllm_maxlen: 8192
# vllm_gpu_util: 0.8
# vllm_max_lora_rank: 128

# device_map: cuda:0


